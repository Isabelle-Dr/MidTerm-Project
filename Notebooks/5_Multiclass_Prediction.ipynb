{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multiclass Prediction\n",
    "\n",
    "The purpose of this notebook is to provide prediction for flight delay cause based on provided flight information."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**INPUT**: flights_test.csv <br>\n",
    "**INPUT**: label_encoders.pkl, scaler.pkl, pca.pkl and model_reg.pkl <br>\n",
    "**OUTPUT**: multiclass_submission.csv <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle \n",
    "import datetime\n",
    "import calendar\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reading the Data\n",
    "Create 2 data frames <br>\n",
    "1. To be transformed and used in model to predict \n",
    "2. As the output file framework"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read csv\n",
    "df = pd.read_csv(\"flights_test_week.csv\")\n",
    "df.drop(columns = 'Unnamed: 0', inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_submission = df.copy()\n",
    "df_submission = df_submission[[\"fl_date\",\"mkt_carrier\",\"mkt_carrier_fl_num\",\"origin\",\"dest\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_model = df.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prepping the Data\n",
    "on the df_model we will perform all the same steps we performed on our training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def get_month(date):\n",
    "    \"\"\"Returns the month the flight occurs\n",
    "    INPUT date in form YYYY-MM-DD\n",
    "    RETURNS month\"\"\"\n",
    "    DATE = datetime.datetime.strptime(date, \"%Y-%m-%d\")\n",
    "    return DATE.month\n",
    "\n",
    "def get_day_of_week(date):\n",
    "    \"\"\"Returns the day of the week\n",
    "    INPUT date in the form YYYY-MM-DD\n",
    "    RETURNS number of day of the week:\n",
    "            where 0 = Monday and 6 = Sunday\"\"\"\n",
    "    DATE = datetime.datetime.strptime(date, \"%Y-%m-%d\")\n",
    "    return DATE.weekday()\n",
    "\n",
    "calendar.setfirstweekday(6)\n",
    "\n",
    "def get_week_of_month(date):\n",
    "    date = str(date).split(\"-\")\n",
    "    year, month, day = int(date[0]), int(date[1]), int(date[2])\n",
    "    x = np.array(calendar.monthcalendar(year, month))\n",
    "    week_of_month = np.where(x==day)[0][0] + 1\n",
    "    return(week_of_month)\n",
    "\n",
    "def check_codeshare(branded_codeshare):\n",
    "    words = branded_codeshare.split(\"_\")\n",
    "    if len(words) == 2:\n",
    "        return 1\n",
    "    return 0\n",
    "\n",
    "def check_time_block(time):\n",
    "    \"\"\"Determine the hour of the day\n",
    "    INPUT time HHMM\n",
    "    RETURNS hour 0-23 where 0 == 12am and 23 == 11pm\"\"\"\n",
    "    if type(time) == 'numpy.ndarray':\n",
    "        time = time.astype(int)\n",
    "    time = int(time)\n",
    "    \n",
    "    t = time // 100\n",
    "    if t == 0:\n",
    "        return 0\n",
    "    return t-1\n",
    "\n",
    "def define_haul_length(distance):\n",
    "    \"\"\"Determine the haul length of a given distance\n",
    "    INPUT distance (in miles)\n",
    "    RETURNS {0: short haul, 1: medium haul, 2: long haul}\"\"\"\n",
    "    \n",
    "    if distance < 700:\n",
    "        return 0 \n",
    "    elif distance < 3000:\n",
    "        return 1\n",
    "    else: \n",
    "        return 2\n",
    "    \n",
    "def mkt_op_combo(mkt_unique, op_unique):\n",
    "    \"\"\"Output a string for the unique combination of the mkt_unique and op_unique\n",
    "        INPUT strings mkt_unique and op_unique\n",
    "        RETURNS string of unique combo\"\"\"\n",
    "    combo = mkt_unique+op_unique\n",
    "    return combo\n",
    "\n",
    "def flight_type(fl_num):\n",
    "    \"\"\"Takes in a fl_num and returns the type of flight\n",
    "        INPUT fl_num\n",
    "        RETURNs flight_type \n",
    "                2: premium, 1 : regular, 0 : regional, ferry, codeshare\"\"\"\n",
    "    fl_num = str(fl_num)\n",
    "    if len(fl_num) < 3:\n",
    "        return 2 #preimum\n",
    "    if len(fl_num) == 3:\n",
    "        return 1 #reg\n",
    "    else: \n",
    "        return 0 #regional affiliate, ferry, codeshare, etc.\n",
    "\n",
    "def get_hist_m_dep_delay(dep_hour):\n",
    "    \"\"\"returns the mean dep_delay for the hour based on 2018-2019 data\n",
    "        INPUT departure hour\n",
    "        OUTPUT historical_mean_dep_delay\"\"\"\n",
    "    historical_delays = {0: 6.711716493969764, 1: 9.675249362096961, 2: 10.619793205317578, 3: 6.630692167577413, 4: -0.4136475056746801,\n",
    "                         5: 0.11429594186434255, 6: 1.6161646966248562, 7: 2.9157571077032296, 8: 4.135963064069914, 9: 5.26489329589765,\n",
    "                         10: 6.13392546097791, 11: 7.0181790875984875, 12: 8.131680643107183, 13: 9.510919588229374, 14: 10.304524506138106,\n",
    "                         15: 11.336050018124949, 16: 12.382205588783819, 17: 13.536146413960237, 18: 13.756275088751552, 19: 13.289175306396258,\n",
    "                         20: 12.634817154337778, 21: 10.544540416974117, 22: 7.987786063255336}\n",
    "    hour = int(dep_hour)\n",
    "    return historical_delays[hour]\n",
    "\n",
    "def get_hist_m_arr_delay(dep_hour):\n",
    "    \"\"\"returns the mean arr_delay for the hour based on 2018-2019 data\n",
    "        INPUT departure hour\n",
    "        OUTPUT historical_mean_arr_delay\"\"\"\n",
    "    historical_delays = {0: -1.6642602344148123, 1: 3.440501043841336, 2: 4.343870014771049, 3: 1.3802367941712204, 4: -5.484170909895949,\n",
    "                         5: -4.606989162142505, 6: -2.907391092361358, 7: -1.8630207558845115, 8: -1.085556598557783, 9: 0.08580366114366288,\n",
    "                         10: 0.5798795108102116, 11: 2.115288435274042, 12: 3.1173279785990315, 13: 4.805705640109731, 14: 5.449820220021156,\n",
    "                         15: 6.739257741261025, 16: 7.6573414085094385, 17: 8.877695016385436, 18: 8.378205975005564, 19: 7.965689735642226,\n",
    "                         20: 6.8922934459978995, 21: 4.922862682118726, 22: 0.5166495242993058}\n",
    "    \n",
    "    hour = int(dep_hour)\n",
    "    return historical_delays[hour]\n",
    "\n",
    "def get_hist_med_dep_delay(dep_hour):\n",
    "    \"\"\"returns the median dep_delay for the hour based on 2018-2019 data\n",
    "        INPUT departure hour\n",
    "        OUTPUT historical_median_dep_delay\"\"\"\n",
    "    historical_delays = {0: -2.0, 1: -2.0, 2: -3.0, 3: -4.0, 4: -4.0, 5: -4.0, 6: -4.0, 7: -3.0, 8: -3.0, 9: -3.0, 10: -2.0, 11: -2.0,\n",
    "                         12: -2.0, 13: -1.0, 14: -1.0, 15: -1.0, 16: -1.0, 17: -1.0, 18: -1.0, 19: -1.0, 20: -1.0, 21: -1.0, 22: -2.0}\n",
    "    hour = int(dep_hour)\n",
    "    return historical_delays[hour]\n",
    "\n",
    "def get_hist_med_arr_delay(dep_hour):\n",
    "    \"\"\"returns the median arr_delay for the hour based on 2018-2019 data\n",
    "        INPUT departure hour\n",
    "        OUTPUT historical_med_arr_delay\"\"\"\n",
    "    historical_delays = {0: -9.0, 1: -6.0, 2: -6.0, 3: -7.0, 4: -9.0, 5: -9.0, 6: -8.0, 7: -8.0, 8: -7.0, 9: -7.0, 10: -7.0, 11: -6.0,\n",
    "                         12: -6.0, 13: -5.0, 14: -5.0, 15: -4.0, 16: -4.0, 17: -3.0, 18: -3.0, 19: -3.0, 20: -4.0, 21: -4.0, 22: -7.0}\n",
    "    hour = int(dep_hour)\n",
    "    return historical_delays[hour]\n",
    "\n",
    "def get_delay_type(carrier_delay, weather_delay, nas_delay, security_delay, late_aircraft_delay):\n",
    "    \"\"\"Takes in all potential delay causes and returns the primary cause\n",
    "    in case of 2 identical delays the first is returned\n",
    "    INPUT carrier_delay, weather_delay, nas_delay, security_delay, late_aircraft_delay\n",
    "    RETURNS {0 : no delay cause noted,\n",
    "            1 : carrier_delay,\n",
    "            2 : weather_delay,\n",
    "            3 : NAS_delay,\n",
    "            4 : security_delay,\n",
    "            5 : late_aircraft_delay}\"\"\"\n",
    "    \n",
    "    if carrier_delay == weather_delay == nas_delay == security_delay == late_aircraft_delay == 0:\n",
    "        return 0\n",
    "    \n",
    "    delays = {}\n",
    "    delays[1] = carrier_delay\n",
    "    delays[2] = weather_delay\n",
    "    delays[3] = nas_delay\n",
    "    delays[4] = security_delay\n",
    "    delays[5] = late_aircraft_delay\n",
    "    \n",
    "    return max(delays, key=delays.get)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_model.drop(columns = ['mkt_carrier', 'tail_num', 'op_carrier_fl_num', \n",
    "                         'origin_airport_id', 'dest_airport_id', 'dup', \n",
    "                         'flights'], inplace = True)\n",
    "\n",
    "#fl_month\n",
    "df_model.loc[:,'fl_month'] = df_model['fl_date'].apply(get_month)\n",
    "#fl_day_of_week\n",
    "df_model.loc[:,'fl_day_of_week'] = df_model['fl_date'].apply(get_day_of_week)\n",
    "#week of month\n",
    "df_model.loc[:,'fl_week_of_month'] = df_model['fl_date'].apply(get_week_of_month)\n",
    "#drop_fl_date\n",
    "df_model.drop(columns = 'fl_date', inplace=True)\n",
    "\n",
    "#get mkt_op_combo\n",
    "df_model.loc[:,\"mkt_op_combo\"] = df_model.apply(lambda x: mkt_op_combo(x.mkt_unique_carrier, \n",
    "                                                                       x.op_unique_carrier), \n",
    "                                                axis=1)\n",
    "df_model.drop(columns = ['mkt_unique_carrier', 'op_unique_carrier'], inplace = True)\n",
    "\n",
    "df_model.loc[:,\"branded_code_share\"] = df_model[\"branded_code_share\"].apply(check_codeshare)\n",
    "\n",
    "#get fl_type\n",
    "df_model.loc[:,\"fl_type\"] = df_model[\"mkt_carrier_fl_num\"].apply(flight_type)\n",
    "\n",
    "df_model.drop(columns = 'mkt_carrier_fl_num', inplace=True)\n",
    "\n",
    "df_model.loc[:,'crs_dep_time'] = df_model['crs_dep_time'].apply(check_time_block)\n",
    "df_model.loc[:,'m_hist_dep_delay'] = df_model['crs_dep_time'].apply(get_hist_m_dep_delay)\n",
    "df_model.loc[:,'med_hist_dep_delay'] = df_model['crs_dep_time'].apply(get_hist_med_dep_delay)\n",
    "df_model.loc[:,'m_hist_arr_delay'] = df_model['crs_dep_time'].apply(get_hist_m_arr_delay)\n",
    "df_model.loc[:,'med_hist_arr_delay'] = df_model['crs_dep_time'].apply(get_hist_med_arr_delay)\n",
    "\n",
    "df_model.loc[:,'crs_arr_time'] = df_model['crs_arr_time'].apply(check_time_block)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "air_time was carried in training despite being a prediction factor as such due to time limitations we have replaced that column with the average from that column to allow completion of the assignment, if possible we would have returned to the error to correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_model.insert (6, \"air_time\", 106.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load in encoders \n",
    "loaded_origin = pickle.load(open('Revamp/origin_encoder.pkl', 'rb'))\n",
    "loaded_dest = pickle.load(open('Revamp/dest_encoder.pkl', 'rb'))\n",
    "loaded_mktopcombo = pickle.load(open('Revamp/mkt_op_combo.pickle', 'rb'))\n",
    "df_model.loc[:,\"origin\"] = loaded_origin.transform(df_model.origin)\n",
    "df_model.loc[:,\"dest\"] = loaded_dest.transform(df_model.dest)\n",
    "df_model.loc[:,\"mkt_op_combo\"] = loaded_mktopcombo.transform(df_model.mkt_op_combo)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Scaling the Data\n",
    "we must scale our model using the same scaler used on our training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load in encoder\n",
    "loaded_scale = pickle.load(open('Revamp/scaler.pkl', 'rb'))\n",
    "\n",
    "X_scaled = loaded_scale.transform(df_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dimensionality Reduction\n",
    "we must reduce our features using the same pca() as determined on our training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_values = X_scaled.copy()\n",
    "#load in the pca\n",
    "loaded_pca = pickle.load(open('pca.pkl', 'rb'))\n",
    "component = loaded_pca.transform(X_scaled)\n",
    "w_transpose = np.transpose(loaded_pca.components_)\n",
    "reduced_feat = np.matmul(data_values, w_transpose)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Running our Model\n",
    "now we will run our trained model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load in the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prepping the Submission File\n",
    "we will merge our y_pred with our df_submission for the output csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_col = pd.DataFrame(data = y_pred,\n",
    "                    columns = \"predicted_delay_type\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def define_delay_type(delay):\n",
    "    if delay == 0:\n",
    "        return \"unknown or unreported cause\"\n",
    "    elif delay == 1: \n",
    "        return \"carrier_delay\"\n",
    "    elif delay == 2:\n",
    "        return \"weather_delay\"\n",
    "    elif delay == 3:\n",
    "        return \"nas_delay\"\n",
    "    elif delay == 4:\n",
    "        return \"security_delay\"\n",
    "    else:\n",
    "        return \"late_aircraft_delay\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_col[:,\"predicted_delay_type\"] = y_col[\"predicted_delay_type\"].apply(define_delay_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = df_submission.merge(y_col, right_index = True, left_index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output.to_csv(\"multiclass_submission.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
