{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Multiclass classification\n",
    "**Goal:** predict the type of delay for delayed flights  \n",
    "\n",
    "**Target variables:** \n",
    "- `CARRIER_DELAY`\n",
    "- `WEATHER_DELAY`\n",
    "- `NAS_DELAY`\n",
    "- `SECURITY_DELAY`\n",
    "- `LATE_AIRCRAFT_DELAY`  \n",
    "\n",
    "**Notes**:  \n",
    "\n",
    "Train this model on a dataset containing delayed flights. We might have unbalanced representation between.  classes, check class representation in the data\n",
    "\n",
    "**Steps**:\n",
    "1. Pick evaluation metrics\n",
    "2. Spot check different algos\n",
    "3. Tune hyperparameters using grid search on 2-3 selected algos\n",
    "4. Compare them based on the selected metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1. Pick evaluation metrics\n",
    "Performance measures for multi-class classification  \n",
    "**F1 score**  \n",
    "**Accuracy**  \n",
    "**Precision-Recall AUC**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2. Spot check different algos (using K-Folds on sample data)\n",
    "\n",
    "### Step 2.1 Spot check regular algorythms\n",
    "\n",
    "- Naive algorythm (used as a baseline model):  \n",
    "Predict the majority class for all\n",
    "\n",
    "- Linear algorythms:  \n",
    "Logistic Regression  \n",
    "LDA  \n",
    "Support Vector Machines\n",
    "Naive Bayes\n",
    "\n",
    "- Non linear algos:  \n",
    "k-Nearest Neighbors  \n",
    "\n",
    "- Ensemble algorythms:  \n",
    "Random forest  \n",
    "Stochastic Gradient Boosting  \n",
    " *Optional: custom ensemble*\n",
    "\n",
    "\n",
    "### Step 2.2 Spot check imbalanced classification algos. Use those techniques on the ML algos to see if it improves performance\n",
    "\n",
    "- Data sampling  \n",
    "Oversampler and Undersampler method: SMOTE combined with RandomUnderSampler on the training datasets in this step [Article on how to perform SMOTE](https://machinelearningmastery.com/smote-oversampling-for-imbalanced-classification/)\n",
    "\n",
    "- Probability tuning (custom threshold) on the algos that can give probabilities as outputs  \n",
    "Logistic Regression \n",
    "LDA \n",
    "\n",
    "- *Optional: Try a [calibration algo on the predicted prbobabilities](https://machinelearningmastery.com/calibrated-classification-model-in-scikit-learn/)*\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3. Hyperparameter tuning\n",
    "Use Grid Search to tune the selected algo (on the whole dataframe?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
