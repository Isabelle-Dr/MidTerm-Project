{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Binary classification\n",
    "**Goal:** The goal is to predict if the flight will be cancelled  \n",
    "\n",
    "**Target variables:** \n",
    "- `CANCELLED` \n",
    "\n",
    "**Notes**:  \n",
    "\n",
    "2% of flights are cancelled. it's a highly imbalanced dataset. We will want to predict probabilities with custom threshold.  \n",
    "[Article on framework for highly imbalanced datasets](https://machinelearningmastery.com/framework-for-imbalanced-classification-projects/)\n",
    "\n",
    "**Steps**:\n",
    "1. Pick evaluation metrics\n",
    "2. Spot check different algos\n",
    "3. Tune hyperparameters using grid search on 2-3 selected algos\n",
    "4. Compare them based on the selected metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1. Pick evaluation metrics\n",
    "**Brier score** and **Brier skill score** (because we will be using probabilities in some models)  \n",
    "**Precision-Recall AUC** (because positive class is more important)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2. Spot check different algos (using K-Folds on sample data)\n",
    "\n",
    "### Step 2.1 Spot check regular algorythms\n",
    "\n",
    "- Naive algorythm (used as a baseline model):  \n",
    "Predict the minority class for all\n",
    "\n",
    "- Linear algorythms:  \n",
    "Logistic Regression  \n",
    "LDA  \n",
    "- Non linear algos:  \n",
    "k-Nearest Neighbors  \n",
    "\n",
    "- Ensemble algorythms:  \n",
    "Random forest  \n",
    "Stochastic Gradient Boosting   \n",
    " *Optional: custom ensemble*\n",
    "\n",
    "- Other\n",
    "One-Class Support Vector Machines (usually used for outlier detection but can be used to do classification)\n",
    "\n",
    "### Step 2.2 Spot check imbalanced classification algos. Use those techniques on the ML algos to see if it improves performance\n",
    "\n",
    "- Data sampling  \n",
    "Oversampler and Undersampler method: SMOTE combined with RandomUnderSampler on the training datasets in this step [Article on how to perform SMOTE](https://machinelearningmastery.com/smote-oversampling-for-imbalanced-classification/)\n",
    "\n",
    "- Probability tuning (custom threshold) on the algos that can give probabilities as outputs  \n",
    "Logistic Regression \n",
    "LDA \n",
    "\n",
    "- Optional: Try a [calibration algo on the predicted prbobabilities](https://machinelearningmastery.com/calibrated-classification-model-in-scikit-learn/)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3. Hyperparameter tuning\n",
    "Use Grid Search to tune the selected algo (on the whole dataframe?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
